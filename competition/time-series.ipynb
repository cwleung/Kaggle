{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt        \nimport seaborn as sns\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-17T18:07:10.559081Z","iopub.execute_input":"2022-04-17T18:07:10.559702Z","iopub.status.idle":"2022-04-17T18:07:11.526783Z","shell.execute_reply.started":"2022-04-17T18:07:10.559583Z","shell.execute_reply":"2022-04-17T18:07:11.525602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/store-sales-time-series-forecasting/'\nos.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:11.528475Z","iopub.execute_input":"2022-04-17T18:07:11.528785Z","iopub.status.idle":"2022-04-17T18:07:11.53943Z","shell.execute_reply.started":"2022-04-17T18:07:11.528752Z","shell.execute_reply":"2022-04-17T18:07:11.538332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_oil = pd.read_csv(path+'oil.csv')\ntrain_data = pd.read_csv(path+'train.csv', index_col=0)\ntest_data = pd.read_csv(path+'test.csv', index_col=0)\nsamp_subm = pd.read_csv(path+'sample_submission.csv')\ndata_holi = pd.read_csv(path+'holidays_events.csv')\ndata_store =  pd.read_csv(path+'stores.csv')\ndata_trans = pd.read_csv(path+'transactions.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:11.541034Z","iopub.execute_input":"2022-04-17T18:07:11.541553Z","iopub.status.idle":"2022-04-17T18:07:14.520593Z","shell.execute_reply.started":"2022-04-17T18:07:11.541494Z","shell.execute_reply":"2022-04-17T18:07:14.519582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of data_oil samples: {data_oil.shape}')\nprint(f'Number of train_data samples: {train_data.shape}')\nprint(f'Number of test_data samples: {test_data.shape}')\nprint(f'Number of samp_subm samples: {samp_subm.shape}')\nprint(f'Number of data_holi samples: {data_holi.shape}')\nprint(f'Number of data_store samples: {data_store.shape}')\nprint(f'Number of data_trans samples: {data_trans.shape}')\nprint(train_data.info())\nprint(train_data.columns)\nprint(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:14.522731Z","iopub.execute_input":"2022-04-17T18:07:14.52302Z","iopub.status.idle":"2022-04-17T18:07:14.550085Z","shell.execute_reply.started":"2022-04-17T18:07:14.522986Z","shell.execute_reply":"2022-04-17T18:07:14.549046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_trans.head())\nprint(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:14.551417Z","iopub.execute_input":"2022-04-17T18:07:14.551679Z","iopub.status.idle":"2022-04-17T18:07:14.563221Z","shell.execute_reply.started":"2022-04-17T18:07:14.551647Z","shell.execute_reply":"2022-04-17T18:07:14.562214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data['store_nbr'].count())\nprint(train_data['store_nbr'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:14.564666Z","iopub.execute_input":"2022-04-17T18:07:14.564993Z","iopub.status.idle":"2022-04-17T18:07:14.604437Z","shell.execute_reply.started":"2022-04-17T18:07:14.564961Z","shell.execute_reply":"2022-04-17T18:07:14.603255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_oil.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:14.606178Z","iopub.execute_input":"2022-04-17T18:07:14.607033Z","iopub.status.idle":"2022-04-17T18:07:14.616546Z","shell.execute_reply.started":"2022-04-17T18:07:14.60697Z","shell.execute_reply":"2022-04-17T18:07:14.615488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Equador's economy is dependent on the crude oil price. Let's examine first the relationship between crude oil and grocery sales and transactions.","metadata":{}},{"cell_type":"code","source":"ax = data_oil.set_index('date').plot(figsize = (16, 8))\nax.set_xlabel('Date', fontsize = 'large')\nax.set_ylabel(\"Crude Oil\", fontsize = 'large')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:14.618251Z","iopub.execute_input":"2022-04-17T18:07:14.618943Z","iopub.status.idle":"2022-04-17T18:07:14.932198Z","shell.execute_reply.started":"2022-04-17T18:07:14.618895Z","shell.execute_reply":"2022-04-17T18:07:14.931101Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\n#daily_avg_sales['weekly_avg_sales'] = daily_avg_sales['sales'].rolling(window=7).mean()\navg_sales['weekly_avg_sales'] = avg_sales['sales'].ewm(span=7, adjust=False).mean()\n#ax = daily_avg_sales.set_index('date').plot(figsize = (16, 8))\nax1 = avg_sales.plot(x= 'date', y= ['sales', 'weekly_avg_sales'], figsize=(18,6))\n\navg_transactions = data_trans.groupby('date').agg({'transactions': 'mean'}).reset_index()\n#avg_transaction['weekly_avg_sales'] = avg_transaction['transactions'].rolling(window=7).mean()\navg_transactions['weekly_avg_transactions'] = avg_transactions['transactions'].ewm(span=7, adjust=False).mean()\n\nax2 = avg_transactions.plot(x= 'date', y= ['transactions', 'weekly_avg_transactions'], figsize=(18,6))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-04-17T18:07:14.93356Z","iopub.execute_input":"2022-04-17T18:07:14.933819Z","iopub.status.idle":"2022-04-17T18:07:15.859044Z","shell.execute_reply.started":"2022-04-17T18:07:14.93379Z","shell.execute_reply":"2022-04-17T18:07:15.858018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_oil.head())\nprint(avg_sales.head())\nprint(avg_transactions.head())","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-04-17T18:07:15.862565Z","iopub.execute_input":"2022-04-17T18:07:15.863212Z","iopub.status.idle":"2022-04-17T18:07:15.87719Z","shell.execute_reply.started":"2022-04-17T18:07:15.863158Z","shell.execute_reply":"2022-04-17T18:07:15.876172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_oil['sales'] = avg_sales['sales']\ndata_oil['transactions'] = avg_transactions['transactions']\n#print(data_oil.head())\ndata_oil.corr()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:15.879727Z","iopub.execute_input":"2022-04-17T18:07:15.879967Z","iopub.status.idle":"2022-04-17T18:07:15.900785Z","shell.execute_reply.started":"2022-04-17T18:07:15.87994Z","shell.execute_reply":"2022-04-17T18:07:15.900094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation between oil and sales and transaction suggests that the country's economic status and everyday grocery consumption do not have a particular relationship.","metadata":{}},{"cell_type":"markdown","source":"# Let's check items that are most sold and the promotion to see which items influence the most for the total sales.","metadata":{}},{"cell_type":"code","source":"print(train_data.family.unique())\nprint(len(train_data.family.unique()))\ntrain_data['family'] = train_data['family'].astype('category')\ntrain_data['family_category'] = train_data['family'].cat.codes\n\nfamily_category = dict( zip( train_data['family'].cat.codes, train_data['family'] ) )\nfamily_category","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:15.90244Z","iopub.execute_input":"2022-04-17T18:07:15.902974Z","iopub.status.idle":"2022-04-17T18:07:17.038112Z","shell.execute_reply.started":"2022-04-17T18:07:15.902927Z","shell.execute_reply":"2022-04-17T18:07:17.037108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_grouped_family_types = train_data.groupby(['family_category']).mean()[['sales', 'onpromotion']]\n\n\ndata_grouped_family_types['%_s'] = 100 * data_grouped_family_types['sales'] / data_grouped_family_types['sales'].sum()\ndata_grouped_family_types['%_s'] = data_grouped_family_types['%_s'].round(decimals = 3)\n\n\npercent = 100 * data_grouped_family_types['sales'] / data_grouped_family_types['sales'].sum()\npercent = percent.round(decimals = 3)\npatches, texts = plt.pie(data_grouped_family_types['%_s'], startangle=90, radius=1.5)\n\n\nlables_2 = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(family_category.values(), percent)]\n\n\nsort_legend = True\nif sort_legend:\n    patches, labels, dummy =  zip(*sorted(zip(patches, lables_2, data_grouped_family_types['%_s']),\n                                          key=lambda x: x[2],\n                                          reverse=True))\n    \nplt.legend(patches, labels, loc='best', bbox_to_anchor=(-0.1, 1.),\n           fontsize=8)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:17.039905Z","iopub.execute_input":"2022-04-17T18:07:17.040298Z","iopub.status.idle":"2022-04-17T18:07:18.262003Z","shell.execute_reply.started":"2022-04-17T18:07:17.040246Z","shell.execute_reply":"2022-04-17T18:07:18.261301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_grouped_family_types = train_data.groupby(['family_category']).mean()[['sales', 'onpromotion']]\n\n\ndata_grouped_family_types['%_p'] = 100 * data_grouped_family_types['onpromotion'] / data_grouped_family_types['onpromotion'].sum()\ndata_grouped_family_types['%_p'] = data_grouped_family_types['%_p'].round(decimals = 3)\n\n\npercent = 100 * data_grouped_family_types['onpromotion'] / data_grouped_family_types['onpromotion'].sum()\npercent = percent.round(decimals = 3)\npatches, texts = plt.pie(data_grouped_family_types['%_p'], startangle=90, radius=1.5)\n\n\nlables_2 = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(family_category.values(), percent)]\n\n\nsort_legend = True\nif sort_legend:\n    patches, labels, dummy =  zip(*sorted(zip(patches, lables_2, data_grouped_family_types['%_p']),\n                                          key=lambda x: x[2],\n                                          reverse=True))\n    \nplt.legend(patches, labels, loc='best', bbox_to_anchor=(-0.1, 1.),\n           fontsize=8)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-04-17T18:07:18.263121Z","iopub.execute_input":"2022-04-17T18:07:18.26391Z","iopub.status.idle":"2022-04-17T18:07:19.359424Z","shell.execute_reply.started":"2022-04-17T18:07:18.263863Z","shell.execute_reply":"2022-04-17T18:07:19.358364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The top 5 most sold are Grocery, beverages, cleaning, dairy, and produce. Grocery + beverage account for more than 50% of total sales. ","metadata":{}},{"cell_type":"markdown","source":"# Let's check sales in different time frames.","metadata":{}},{"cell_type":"code","source":"train_data['date'] = pd.to_datetime(train_data['date'])\ntrain_data['day_of_week'] = train_data['date'].dt.dayofweek\ntrain_data['month'] = train_data['date'].dt.month\ntrain_data['year'] = train_data['date'].dt.year","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:19.361297Z","iopub.execute_input":"2022-04-17T18:07:19.361884Z","iopub.status.idle":"2022-04-17T18:07:20.608609Z","shell.execute_reply.started":"2022-04-17T18:07:19.361835Z","shell.execute_reply":"2022-04-17T18:07:20.60756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_grouped_day = train_data.groupby(['day_of_week']).mean()['sales']\ndata_grouped_month = train_data.groupby(['month']).mean()['sales']\ndata_grouped_year = train_data.groupby(['year']).mean()['sales']\n\nplt.subplots(3,1, figsize=(20,5))\nplt.subplot(131)\nplt.title('sales - day')\ndata_grouped_day.plot(kind='bar', stacked=True)\nplt.subplot(132)\nplt.title('sales - month')\ndata_grouped_month.plot(kind='bar', stacked=True)\nplt.subplot(133)\nplt.title('sales - year')\ndata_grouped_year.plot(kind='bar', stacked=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:20.610302Z","iopub.execute_input":"2022-04-17T18:07:20.610843Z","iopub.status.idle":"2022-04-17T18:07:22.182812Z","shell.execute_reply.started":"2022-04-17T18:07:20.6108Z","shell.execute_reply":"2022-04-17T18:07:22.181833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sales analysis in different time frame\n * In a daily basis, Saturday and Sunday show the highest sales.\n * In a month basis, December sales are particularly strong.\n * In a yearly basis, It is growing at steady pace.","metadata":{}},{"cell_type":"markdown","source":"# Check sales for holidays","metadata":{}},{"cell_type":"code","source":"print(data_holi['type'].unique())\nprint(data_holi['type'].value_counts())\n\nday_type = data_holi[['date', 'type']]\navg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\n\nday_type['date'] = pd.to_datetime(day_type['date'])\navg_sales['date'] = pd.to_datetime(avg_sales['date'])\n\n#print(day_type.head())\n#print(avg_sales.head())\n\ndf = pd.merge_asof(day_type, avg_sales, on = 'date')\ndf.dropna(inplace= True)\ndf.reset_index(drop = True, inplace= True)\n\n#print(df.head())\n\ndf_1 = df.groupby(['type']).mean()['sales']\naverage_holiday_sales = df_1.mean()\n#print(df_1.head())\n\nprint(f'average holiday sales is {average_holiday_sales}')\n\ndf_1.plot(kind='bar', figsize = (12,6)).set_title('average holiday sales')","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-04-17T18:07:22.184322Z","iopub.execute_input":"2022-04-17T18:07:22.184908Z","iopub.status.idle":"2022-04-17T18:07:22.505863Z","shell.execute_reply.started":"2022-04-17T18:07:22.184865Z","shell.execute_reply":"2022-04-17T18:07:22.505205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The average holiday sales are equivalent to Saturday and Sunday sales.","metadata":{}},{"cell_type":"markdown","source":"# Let's follow the template provided by Kaggle moderator for future sales prediction. Start with linear regression\nhttps://www.kaggle.com/ryanholbrook/linear-regression-with-time-series/notebook","metadata":{}},{"cell_type":"code","source":"avg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\navg_sales['Time'] = np.arange(len(avg_sales.index))\navg_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:22.507127Z","iopub.execute_input":"2022-04-17T18:07:22.507384Z","iopub.status.idle":"2022-04-17T18:07:22.579915Z","shell.execute_reply.started":"2022-04-17T18:07:22.507354Z","shell.execute_reply":"2022-04-17T18:07:22.578987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(12, 6),\n    titlesize=18,\n    titleweight='bold',\n)\n\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\n\n# Use it for the Lag_1 plot later.\nplot_params = dict(\n    color = '0.75',\n    style = \".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n\n%config InlineBackend.figure_format = 'retina' # You can remove\n\nfig, ax = plt.subplots()\nax.plot('Time', 'sales', data=avg_sales, color='0.75')\nax = sns.regplot(x='Time', y='sales', data=avg_sales, ci=None, scatter_kws=dict(color='0.25'))\nax.set_title('Time Plot of sales');","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:22.581412Z","iopub.execute_input":"2022-04-17T18:07:22.581648Z","iopub.status.idle":"2022-04-17T18:07:23.161139Z","shell.execute_reply.started":"2022-04-17T18:07:22.581622Z","shell.execute_reply":"2022-04-17T18:07:23.160123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_sales['Lag_1'] = avg_sales['sales'].shift(1)\navg_sales = avg_sales.reindex(columns = ['date','sales', 'Lag_1','Time'])\navg_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:23.162536Z","iopub.execute_input":"2022-04-17T18:07:23.162776Z","iopub.status.idle":"2022-04-17T18:07:23.178749Z","shell.execute_reply.started":"2022-04-17T18:07:23.162746Z","shell.execute_reply":"2022-04-17T18:07:23.177906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax = sns.regplot(x = 'Lag_1', y = 'sales', data = avg_sales, ci = None, scatter_kws = dict(color='0.25'))\nax.set_aspect('equal')\nax.set_title('Lag Plot of sales')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:23.179746Z","iopub.execute_input":"2022-04-17T18:07:23.180367Z","iopub.status.idle":"2022-04-17T18:07:23.615157Z","shell.execute_reply.started":"2022-04-17T18:07:23.180333Z","shell.execute_reply":"2022-04-17T18:07:23.614164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# Training data\nX = avg_sales.loc[:, ['Time']] # features\ny = avg_sales.loc[:, 'sales'] # target\n\n# Train the model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Store the fitted values as a time series with the same time index as\n# the training data\ny_pred = pd.Series(model.predict(X), index = X.index)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:23.616589Z","iopub.execute_input":"2022-04-17T18:07:23.616809Z","iopub.status.idle":"2022-04-17T18:07:23.878131Z","shell.execute_reply.started":"2022-04-17T18:07:23.616784Z","shell.execute_reply":"2022-04-17T18:07:23.8772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y.plot(**plot_params)\nax = y_pred.plot(ax=ax, linewidth = 3)\nax.set_title('Time Plot of sales');","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:23.879752Z","iopub.execute_input":"2022-04-17T18:07:23.880624Z","iopub.status.idle":"2022-04-17T18:07:24.401498Z","shell.execute_reply.started":"2022-04-17T18:07:23.880574Z","shell.execute_reply":"2022-04-17T18:07:24.400675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nX = avg_sales.loc[:, ['Lag_1']]\nX.dropna(inplace = True) # drop missing values in the feature set\ny = avg_sales.loc[:, 'sales'] # create the target\ny, X = y.align(X, join = 'inner') # drop corresponding values in target\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:24.403342Z","iopub.execute_input":"2022-04-17T18:07:24.403676Z","iopub.status.idle":"2022-04-17T18:07:24.426189Z","shell.execute_reply.started":"2022-04-17T18:07:24.403639Z","shell.execute_reply":"2022-04-17T18:07:24.425082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(X['Lag_1'], y, '.', color='0.25')\nax.plot(X['Lag_1'], y_pred)\nax.set_aspect('equal')\nax.set_ylabel('sales')\nax.set_xlabel('Lag_1')\nax.set_title('Lag Plot of sales');","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:24.427537Z","iopub.execute_input":"2022-04-17T18:07:24.428141Z","iopub.status.idle":"2022-04-17T18:07:24.821663Z","shell.execute_reply.started":"2022-04-17T18:07:24.428103Z","shell.execute_reply":"2022-04-17T18:07:24.820704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y.plot(**plot_params)\nax = y_pred.plot()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:24.82328Z","iopub.execute_input":"2022-04-17T18:07:24.823894Z","iopub.status.idle":"2022-04-17T18:07:25.448369Z","shell.execute_reply.started":"2022-04-17T18:07:24.823844Z","shell.execute_reply":"2022-04-17T18:07:25.447425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Indeed, linear regression alone can get rid of noise. Chart looks simliar to my 7 days moving average**","metadata":{}},{"cell_type":"markdown","source":"# Trend\n\nhttps://www.kaggle.com/ryanholbrook/trend","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nfrom warnings import simplefilter\n\nsimplefilter(\"ignore\")  # ignore warnings to clean up output cells\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'\n\n# Load the sales dataset\navg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\n#avg_sales = avg_sales.set_index('date')\n#avg_sales.index = pd.to_datetime(avg_sales.index)\navg_sales = avg_sales.set_index('date').to_period(\"D\")\navg_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:25.449713Z","iopub.execute_input":"2022-04-17T18:07:25.44997Z","iopub.status.idle":"2022-04-17T18:07:25.557531Z","shell.execute_reply.started":"2022-04-17T18:07:25.449937Z","shell.execute_reply":"2022-04-17T18:07:25.556588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"moving_average = avg_sales.rolling(\n    window=365,       # 365-day window\n    center=True,      # puts the average at the center of the window\n    min_periods=183,  # choose about half the window size\n).mean()              # compute the mean (could also do median, std, min, max, ...)\n\nax = avg_sales.plot(style=\".\", color=\"0.5\")\nmoving_average.plot(\n    ax=ax, linewidth=3, title=\"sales - 365-Day Moving Average\", legend=False,\n);","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:25.562265Z","iopub.execute_input":"2022-04-17T18:07:25.562583Z","iopub.status.idle":"2022-04-17T18:07:26.103969Z","shell.execute_reply.started":"2022-04-17T18:07:25.562544Z","shell.execute_reply":"2022-04-17T18:07:26.102972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import DeterministicProcess\n\ndp = DeterministicProcess(\n    index=avg_sales.index,  # dates from the training data\n    constant=True,       # dummy feature for the bias (y_intercept)\n    order=1,             # the time dummy (trend)\n    drop=True,           # drop terms if necessary to avoid collinearity\n)\n# `in_sample` creates features for the dates given in the `index` argument\nX = dp.in_sample()\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:26.105362Z","iopub.execute_input":"2022-04-17T18:07:26.105618Z","iopub.status.idle":"2022-04-17T18:07:26.367383Z","shell.execute_reply.started":"2022-04-17T18:07:26.105587Z","shell.execute_reply":"2022-04-17T18:07:26.366435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\ny = avg_sales[\"sales\"]  # the target\n\n# The intercept is the same as the `const` feature from\n# DeterministicProcess. LinearRegression behaves badly with duplicated\n# features, so we need to be sure to exclude it here.\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=X.index)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:26.368749Z","iopub.execute_input":"2022-04-17T18:07:26.369015Z","iopub.status.idle":"2022-04-17T18:07:26.379638Z","shell.execute_reply.started":"2022-04-17T18:07:26.36898Z","shell.execute_reply":"2022-04-17T18:07:26.378703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = avg_sales.plot(style=\".\", color=\"0.5\", title=\"sales - Linear Trend\")\n_ = y_pred.plot(ax=ax, linewidth=3, label=\"Trend\")","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:26.381272Z","iopub.execute_input":"2022-04-17T18:07:26.381524Z","iopub.status.idle":"2022-04-17T18:07:26.903437Z","shell.execute_reply.started":"2022-04-17T18:07:26.381495Z","shell.execute_reply":"2022-04-17T18:07:26.902424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dp.out_of_sample(steps=180)\n\ny_fore = pd.Series(model.predict(X), index=X.index)\n\ny_fore.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:26.904687Z","iopub.execute_input":"2022-04-17T18:07:26.904941Z","iopub.status.idle":"2022-04-17T18:07:26.916047Z","shell.execute_reply.started":"2022-04-17T18:07:26.904909Z","shell.execute_reply":"2022-04-17T18:07:26.91541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = avg_sales[\"2013-01\":].plot(title=\"Tunnel Traffic - Linear Trend Forecast\", **plot_params)\nax = y_pred[\"2013-01\":].plot(ax=ax, linewidth=3, label=\"Trend\")\nax = y_fore.plot(ax=ax, linewidth=3, label=\"Trend Forecast\", color=\"C3\")\n_ = ax.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:26.917311Z","iopub.execute_input":"2022-04-17T18:07:26.917752Z","iopub.status.idle":"2022-04-17T18:07:27.557701Z","shell.execute_reply.started":"2022-04-17T18:07:26.917713Z","shell.execute_reply":"2022-04-17T18:07:27.557001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seasonality","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'\n\n\n# annotations: https://stackoverflow.com/a/49238256/5769929\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\n# Load the sales dataset\navg_sales = train_data.groupby('date').agg({'sales': 'mean'}).reset_index()\navg_sales = avg_sales.set_index('date').to_period(\"D\")\navg_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:27.559081Z","iopub.execute_input":"2022-04-17T18:07:27.559496Z","iopub.status.idle":"2022-04-17T18:07:27.686958Z","shell.execute_reply.started":"2022-04-17T18:07:27.55945Z","shell.execute_reply":"2022-04-17T18:07:27.686076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = avg_sales.copy()\n\n# days within a week\nX['day'] = X.index.dayofweek # the x-axis (freq)\nX['week'] = X.index.week # the seasonal period (period)\n\n# days within a year\nX['dayofyear'] = X.index.dayofyear\nX['year'] = X.index.year\n\nfig, (ax0, ax1) = plt.subplots(2, 1, figsize=(11, 6))\nseasonal_plot(X, y=\"sales\", period=\"week\", freq=\"day\", ax=ax0)\nseasonal_plot(X, y=\"sales\", period=\"year\", freq=\"dayofyear\", ax=ax1);","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:27.688374Z","iopub.execute_input":"2022-04-17T18:07:27.68913Z","iopub.status.idle":"2022-04-17T18:07:36.878042Z","shell.execute_reply.started":"2022-04-17T18:07:27.689091Z","shell.execute_reply":"2022-04-17T18:07:36.877341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_periodogram(avg_sales.sales);\n\ny_deseason = y - y_pred\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodogram(y, ax=ax1)\nax1.set_title(\"Product Sales Frequency Components\")\nax2 = plot_periodogram(y_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:36.879366Z","iopub.execute_input":"2022-04-17T18:07:36.879786Z","iopub.status.idle":"2022-04-17T18:07:38.055194Z","shell.execute_reply.started":"2022-04-17T18:07:36.87974Z","shell.execute_reply":"2022-04-17T18:07:38.054214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfourier = CalendarFourier(freq=\"A\", order=10)  # 10 sin/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=avg_sales.index,\n    constant=True,   # dummy feature for bias (y-intercept)\n    order=1,         # trend ( order 1 means linear)\n    seasonal=True,   # weekly seasonality (indicators)\n    additional_terms=[fourier], # annual seasonality\n    drop=True,       # drop terms to avoid collinearity\n)\n\nX = dp.in_sample() # create features for dates in tunnel.index\n#X.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:38.056832Z","iopub.execute_input":"2022-04-17T18:07:38.057549Z","iopub.status.idle":"2022-04-17T18:07:38.086809Z","shell.execute_reply.started":"2022-04-17T18:07:38.057494Z","shell.execute_reply":"2022-04-17T18:07:38.085666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = avg_sales[\"sales\"]\n\nmodel = LinearRegression(fit_intercept=False)\n_ = model.fit(X, y)\n\ny_pred = pd.Series(model.predict(X), index=y.index)\nX_fore = dp.out_of_sample(steps=180)\ny_fore = pd.Series(model.predict(X_fore), index=X_fore.index)\n\nax = y.plot(color='0.25', style='.', title=\"sales - Seasonal Forecast\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax = y_fore.plot(ax=ax, label=\"Seasonal Forecast\", color='C3')\n_ = ax.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:38.088506Z","iopub.execute_input":"2022-04-17T18:07:38.089495Z","iopub.status.idle":"2022-04-17T18:07:38.767318Z","shell.execute_reply.started":"2022-04-17T18:07:38.089438Z","shell.execute_reply":"2022-04-17T18:07:38.766356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comp_dir = Path('../input/store-sales-time-series-forecasting')\n\nholidays_events = pd.read_csv(\n    comp_dir / \"holidays_events.csv\",\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nholidays_events = holidays_events.set_index('date').to_period('D')\n\n# National and regional holidays in the training set\nholidays = (\n    holidays_events\n    .query(\"locale in ['National', 'Regional']\")\n    .loc['2017':'2017-08-15', ['description']]\n    .assign(description=lambda x: x.description.cat.remove_unused_categories())\n)\n\ndisplay(holidays)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:38.768598Z","iopub.execute_input":"2022-04-17T18:07:38.768847Z","iopub.status.idle":"2022-04-17T18:07:38.803377Z","shell.execute_reply.started":"2022-04-17T18:07:38.768818Z","shell.execute_reply":"2022-04-17T18:07:38.802332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = y_deseason.plot(**plot_params)\nplt.plot_date(holidays.index, y_deseason[holidays.index], color='C3')\nax.set_title('National and Regional Holidays');","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:38.804906Z","iopub.execute_input":"2022-04-17T18:07:38.805177Z","iopub.status.idle":"2022-04-17T18:07:39.393826Z","shell.execute_reply.started":"2022-04-17T18:07:38.805145Z","shell.execute_reply":"2022-04-17T18:07:39.393106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scikit-learn solution\nfrom sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(sparse=False)\n\nX_holidays = pd.DataFrame(\n    ohe.fit_transform(holidays),\n    index=holidays.index,\n    columns=holidays.description.unique(),\n)\n\n\n# Pandas solution\nX_holidays = pd.get_dummies(holidays)\n\n\n# Join to training data\nX2 = X.join(X_holidays, on='date').fillna(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:39.394975Z","iopub.execute_input":"2022-04-17T18:07:39.395869Z","iopub.status.idle":"2022-04-17T18:07:39.412691Z","shell.execute_reply.started":"2022-04-17T18:07:39.395814Z","shell.execute_reply":"2022-04-17T18:07:39.411619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegression().fit(X2, y)\ny_pred = pd.Series(\n    model.predict(X2),\n    index=X2.index,\n    name='Fitted',\n)\n\ny_pred = pd.Series(model.predict(X2), index=X2.index)\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:39.414106Z","iopub.execute_input":"2022-04-17T18:07:39.414973Z","iopub.status.idle":"2022-04-17T18:07:40.135606Z","shell.execute_reply.started":"2022-04-17T18:07:39.414931Z","shell.execute_reply":"2022-04-17T18:07:40.134514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales = pd.read_csv(\n    comp_dir / 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\ny = store_sales.unstack(['store_nbr', 'family']).loc[\"2017\"]\n\n# Create training data\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\nX = dp.in_sample()\nX['NewYear'] = (X.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X, y)\ny_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:40.136895Z","iopub.execute_input":"2022-04-17T18:07:40.137184Z","iopub.status.idle":"2022-04-17T18:07:45.530502Z","shell.execute_reply.started":"2022-04-17T18:07:40.137153Z","shell.execute_reply":"2022-04-17T18:07:45.529228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STORE_NBR = '1'  # 1 - 54\nFAMILY = 'PRODUCE'\n# Uncomment to see a list of product families\n# display(store_sales.index.get_level_values('family').unique())\n\nax = y.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(**plot_params)\nax = y_pred.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(ax=ax)\nax.set_title(f'{FAMILY} Sales at Store {STORE_NBR}');","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:45.532218Z","iopub.execute_input":"2022-04-17T18:07:45.532905Z","iopub.status.idle":"2022-04-17T18:07:46.228225Z","shell.execute_reply.started":"2022-04-17T18:07:45.532855Z","shell.execute_reply":"2022-04-17T18:07:46.227335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\n    comp_dir / 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ndf_test['date'] = df_test.date.dt.to_period('D')\ndf_test = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n\n# Create features for test set\nX_test = dp.out_of_sample(steps=16)\nX_test.index.name = 'date'\nX_test['NewYear'] = (X_test.index.dayofyear == 1)\n\n\ny_submit = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)\ny_submit = y_submit.stack(['store_nbr', 'family'])\ny_submit = y_submit.join(df_test.id).reindex(columns=['id', 'sales'])\ny_submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:46.229794Z","iopub.execute_input":"2022-04-17T18:07:46.230106Z","iopub.status.idle":"2022-04-17T18:07:47.535459Z","shell.execute_reply.started":"2022-04-17T18:07:46.23005Z","shell.execute_reply":"2022-04-17T18:07:47.534278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission.","metadata":{}},{"cell_type":"markdown","source":"# Time Series as Features","metadata":{}},{"cell_type":"code","source":"from learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_lags, make_lags, make_leads\n\nfrom sklearn.metrics import mean_squared_log_error\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nstore_sales = pd.read_csv(\n    comp_dir / 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean() \n    .unstack('family')\n    .loc['2017', ['sales', 'onpromotion']]\n)\n\nmag_sales = family_sales.loc(axis=1)[:, 'MAGAZINES']\n\nstore_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:47.536998Z","iopub.execute_input":"2022-04-17T18:07:47.538044Z","iopub.status.idle":"2022-04-17T18:07:53.137515Z","shell.execute_reply.started":"2022-04-17T18:07:47.537996Z","shell.execute_reply":"2022-04-17T18:07:53.136538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = mag_sales.loc[:, 'sales'].squeeze()\n\nfourier = CalendarFourier(freq='M', order=4)\ndp = DeterministicProcess(\n    constant=True,\n    index=y.index,\n    order=1,\n    seasonal=True,\n    drop=True,\n    additional_terms=[fourier],\n)\nX_time = dp.in_sample()\nX_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_time, y)\ny_deseason = y - model.predict(X_time)\ny_deseason.name = 'sales_deseasoned'\n\nax = y_deseason.plot()\nax.set_title(\"Magazine Sales (deseasonalized)\");","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:53.138865Z","iopub.execute_input":"2022-04-17T18:07:53.139183Z","iopub.status.idle":"2022-04-17T18:07:53.72897Z","shell.execute_reply.started":"2022-04-17T18:07:53.139148Z","shell.execute_reply":"2022-04-17T18:07:53.727844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# YOUR CODE HERE\ny_ma = y.rolling(7, center=True).mean()\n\n\n# Plot\nax = y_ma.plot()\nax.set_title(\"Seven-Day Moving Average\");","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:53.730194Z","iopub.execute_input":"2022-04-17T18:07:53.730415Z","iopub.status.idle":"2022-04-17T18:07:54.306271Z","shell.execute_reply.started":"2022-04-17T18:07:53.730389Z","shell.execute_reply":"2022-04-17T18:07:54.305222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pacf(y_deseason, lags=8);\nplot_lags(y_deseason, lags=8, nrows=2);","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:54.307802Z","iopub.execute_input":"2022-04-17T18:07:54.308106Z","iopub.status.idle":"2022-04-17T18:07:56.890278Z","shell.execute_reply.started":"2022-04-17T18:07:54.308043Z","shell.execute_reply":"2022-04-17T18:07:56.889237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onpromotion = mag_sales.loc[:, 'onpromotion'].squeeze().rename('onpromotion')\n\n# Drop the New Year outlier\nplot_lags(x=onpromotion.iloc[1:], y=y_deseason.iloc[1:], lags=3, leads=3, nrows=1);","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:56.89204Z","iopub.execute_input":"2022-04-17T18:07:56.893119Z","iopub.status.idle":"2022-04-17T18:07:58.313026Z","shell.execute_reply.started":"2022-04-17T18:07:56.893047Z","shell.execute_reply":"2022-04-17T18:07:58.31201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# YOUR CODE HERE: Make features from `y_deseason`\nX_lags = make_lags(y_deseason, lags = 1)\n\n# YOUR CODE HERE: Make features from `onpromotion`\n# You may want to use `pd.concat`\nX_promo = pd.concat([\n    make_lags(onpromotion, lags= 1),\n    onpromotion,\n    make_leads(onpromotion, leads = 1),\n], axis=1)\n\n# YOUR CODE HERE: Make features from `oil`\nX_oil = pd.DataFrame()\n\nX = pd.concat([X_lags, X_promo, X_oil], axis=1).dropna()\ny, X = y.align(X, join='inner')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:58.314423Z","iopub.execute_input":"2022-04-17T18:07:58.314664Z","iopub.status.idle":"2022-04-17T18:07:58.339016Z","shell.execute_reply.started":"2022-04-17T18:07:58.314635Z","shell.execute_reply":"2022-04-17T18:07:58.337619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n\nmodel = LinearRegression(fit_intercept=False).fit(X_train, y_train)\ny_fit = pd.Series(model.predict(X_train), index=X_train.index).clip(0.0)\ny_pred = pd.Series(model.predict(X_valid), index=X_valid.index).clip(0.0)\n\nrmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\nprint(f'Training RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\nax = y_pred.plot(ax=ax, label=\"Forecast\", color='C3')\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:58.341243Z","iopub.execute_input":"2022-04-17T18:07:58.342143Z","iopub.status.idle":"2022-04-17T18:07:59.030323Z","shell.execute_reply.started":"2022-04-17T18:07:58.342087Z","shell.execute_reply":"2022-04-17T18:07:59.02907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_lag = mag_sales.loc[:, 'sales'].shift(1)\nonpromo = mag_sales.loc[:, 'onpromotion']\n\n# 28-day mean of lagged target\nmean_7 = y_lag.rolling(7).mean()\n# YOUR CODE HERE: 14-day median of lagged target\nmedian_14 = y_lag.rolling(14).median()\n# YOUR CODE HERE: 7-day rolling standard deviation of lagged target\nstd_7 = y_lag.rolling(7).std()\n# YOUR CODE HERE: 7-day sum of promotions with centered window\npromo_7 = onpromo.rolling(7, center=True).sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:59.032232Z","iopub.execute_input":"2022-04-17T18:07:59.032997Z","iopub.status.idle":"2022-04-17T18:07:59.048454Z","shell.execute_reply.started":"2022-04-17T18:07:59.032939Z","shell.execute_reply":"2022-04-17T18:07:59.047457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hybrids Models","metadata":{}},{"cell_type":"code","source":"family_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean()\n    .unstack('family')\n    .loc['2017']\n)\n\nfamily_sales.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:59.050384Z","iopub.execute_input":"2022-04-17T18:07:59.050696Z","iopub.status.idle":"2022-04-17T18:08:00.620586Z","shell.execute_reply.started":"2022-04-17T18:07:59.050649Z","shell.execute_reply":"2022-04-17T18:08:00.619634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You'll add fit and predict methods to this minimal class\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:00.622082Z","iopub.execute_input":"2022-04-17T18:08:00.622551Z","iopub.status.idle":"2022-04-17T18:08:00.628166Z","shell.execute_reply.started":"2022-04-17T18:08:00.622508Z","shell.execute_reply":"2022-04-17T18:08:00.627392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(self, X_1, X_2, y):\n    # Train model_1\n    self.model_1.fit(X_1, y)\n\n    # Make predictions\n    y_fit = pd.DataFrame(\n        self.model_1.predict(X_1), \n        index=X_1.index, \n        columns=y.columns,\n    )\n\n    # Compute residuals\n    y_resid = y - y_fit\n    y_resid = y_resid.stack().squeeze() # wide to long\n\n    # Train model_2 on residuals\n    self.model_2.fit(X_2, y_resid)\n\n    # Save column names for predict method\n    self.y_columns = y.columns\n    # Save data for question checking\n    self.y_fit = y_fit\n    self.y_resid = y_resid\n\n\n# Add method to class\nBoostedHybrid.fit = fit","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:00.629334Z","iopub.execute_input":"2022-04-17T18:08:00.629552Z","iopub.status.idle":"2022-04-17T18:08:00.64142Z","shell.execute_reply.started":"2022-04-17T18:08:00.629527Z","shell.execute_reply":"2022-04-17T18:08:00.64068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(self, X_1, X_2):\n    # Predict with model_1\n    y_pred = pd.DataFrame(\n        self.model_1.predict(X_1), \n        index=X_1.index, columns=self.y_columns,\n    )\n    y_pred = y_pred.stack().squeeze()  # wide to long\n\n    # Add model_2 predictions to model_1 predictions\n    y_pred += self.model_2.predict(X_2)\n\n    return y_pred.unstack()\n\n\n# Add method to class\nBoostedHybrid.predict = predict","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:00.642882Z","iopub.execute_input":"2022-04-17T18:08:00.643427Z","iopub.status.idle":"2022-04-17T18:08:00.657081Z","shell.execute_reply.started":"2022-04-17T18:08:00.643383Z","shell.execute_reply":"2022-04-17T18:08:00.656322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Target series\ny = family_sales.loc[:, 'sales']\n\n\n# X_1: Features for Linear Regression\ndp = DeterministicProcess(index=y.index, order=1)\nX_1 = dp.in_sample()\n\n\n# X_2: Features for XGBoost\nX_2 = family_sales.drop('sales', axis=1).stack()  # onpromotion feature\n\n# Label encoding for 'family'\nle = LabelEncoder()  # from sklearn.preprocessing\nX_2 = X_2.reset_index('family')\nX_2['family'] = le.fit_transform(X_2['family'])\n\n# Label encoding for seasonality\nX_2[\"day\"] = X_2.index.day  # values are day of the month","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:00.658594Z","iopub.execute_input":"2022-04-17T18:08:00.659123Z","iopub.status.idle":"2022-04-17T18:08:00.821484Z","shell.execute_reply.started":"2022-04-17T18:08:00.65908Z","shell.execute_reply":"2022-04-17T18:08:00.820787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor\n# YOUR CODE HERE: Create LinearRegression + XGBRegressor hybrid with BoostedHybrid\nmodel = BoostedHybrid(\n    model_1 = LinearRegression(),\n    model_2 = XGBRegressor(),\n)\n\n# YOUR CODE HERE: Fit and predict\nmodel.fit(X_1, X_2, y)\ny_pred = model.predict(X_1, X_2)\n\ny_pred = y_pred.clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:00.822901Z","iopub.execute_input":"2022-04-17T18:08:00.823309Z","iopub.status.idle":"2022-04-17T18:08:01.210672Z","shell.execute_reply.started":"2022-04-17T18:08:00.823273Z","shell.execute_reply":"2022-04-17T18:08:01.209728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model 1 (trend)\nfrom pyearth import Earth\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge\n\n# Model 2\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Boosted Hybrid\n\n# YOUR CODE HERE: Try different combinations of the algorithms above\nmodel = BoostedHybrid(\n    model_1=Ridge(),\n    model_2=KNeighborsRegressor(),\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:01.212345Z","iopub.execute_input":"2022-04-17T18:08:01.212839Z","iopub.status.idle":"2022-04-17T18:08:01.597094Z","shell.execute_reply.started":"2022-04-17T18:08:01.212787Z","shell.execute_reply":"2022-04-17T18:08:01.596126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train, y_valid = y[:\"2017-07-01\"], y[\"2017-07-02\":]\nX1_train, X1_valid = X_1[: \"2017-07-01\"], X_1[\"2017-07-02\" :]\nX2_train, X2_valid = X_2.loc[:\"2017-07-01\"], X_2.loc[\"2017-07-02\":]\n\n# Some of the algorithms above do best with certain kinds of\n# preprocessing on the features (like standardization), but this is\n# just a demo.\nmodel.fit(X1_train, X2_train, y_train)\ny_fit = model.predict(X1_train, X2_train).clip(0.0)\ny_pred = model.predict(X1_valid, X2_valid).clip(0.0)\n\nfamilies = y.columns[0:6]\naxs = y.loc(axis=1)[families].plot(\n    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,\n)\n_ = y_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)\n_ = y_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)\nfor ax, family in zip(axs, families):\n    ax.legend([])\n    ax.set_ylabel(family)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:01.598507Z","iopub.execute_input":"2022-04-17T18:08:01.598776Z","iopub.status.idle":"2022-04-17T18:08:03.898001Z","shell.execute_reply.started":"2022-04-17T18:08:01.598744Z","shell.execute_reply":"2022-04-17T18:08:03.897291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not many people are interested in books during the summer :)) Maybe the trend has changed because of covid lockdown since 2020? ","metadata":{}},{"cell_type":"markdown","source":"# Forecasting with Machine Learning","metadata":{}},{"cell_type":"code","source":"#family_sales.head()\n\ntest = pd.read_csv(\n    comp_dir / 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ntest['date'] = test.date.dt.to_period('D')\ntest = test.set_index(['store_nbr', 'family', 'date']).sort_index()\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:03.899347Z","iopub.execute_input":"2022-04-17T18:08:03.900127Z","iopub.status.idle":"2022-04-17T18:08:03.952368Z","shell.execute_reply.started":"2022-04-17T18:08:03.900083Z","shell.execute_reply":"2022-04-17T18:08:03.951427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom learntools.time_series.utils import (create_multistep_example,\n                                          load_multistep_data,\n                                          make_lags,\n                                          make_multistep_target,\n                                          plot_multistep)\n\ndatasets = load_multistep_data()\n\ndata_tabs = widgets.Tab([widgets.Output() for _ in enumerate(datasets)])\nfor i, df in enumerate(datasets):\n    data_tabs.set_title(i, f'Dataset {i+1}')\n    with data_tabs.children[i]:\n        display(df)\n\ndisplay(data_tabs)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:03.954342Z","iopub.execute_input":"2022-04-17T18:08:03.954877Z","iopub.status.idle":"2022-04-17T18:08:04.17673Z","shell.execute_reply.started":"2022-04-17T18:08:03.954827Z","shell.execute_reply":"2022-04-17T18:08:04.175986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(\"Training Data\", \"\\n\" + \"-\" * 13 + \"\\n\", store_sales)\n#print(\"\\n\")\n#print(\"Test Data\", \"\\n\" + \"-\" * 9 + \"\\n\", test)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:04.177992Z","iopub.execute_input":"2022-04-17T18:08:04.178352Z","iopub.status.idle":"2022-04-17T18:08:04.18251Z","shell.execute_reply.started":"2022-04-17T18:08:04.178313Z","shell.execute_reply":"2022-04-17T18:08:04.18159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = family_sales.loc[:, 'sales']\n\nX = make_lags(y, lags=4).dropna()\n\ny = make_multistep_target(y, steps=16).dropna()\n\ny, X = y.align(X, join='inner', axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:04.183698Z","iopub.execute_input":"2022-04-17T18:08:04.183919Z","iopub.status.idle":"2022-04-17T18:08:04.212205Z","shell.execute_reply.started":"2022-04-17T18:08:04.183893Z","shell.execute_reply":"2022-04-17T18:08:04.21116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nX = (X\n    .stack('family')  # wide to long\n    .reset_index('family')  # convert index to column\n    .assign(family=lambda x: le.fit_transform(x.family))  # label encode\n)\ny = y.stack('family')  # wide to long\n\ndisplay(y)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:04.213658Z","iopub.execute_input":"2022-04-17T18:08:04.213935Z","iopub.status.idle":"2022-04-17T18:08:04.505962Z","shell.execute_reply.started":"2022-04-17T18:08:04.213902Z","shell.execute_reply":"2022-04-17T18:08:04.504985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.multioutput import RegressorChain\n\nmodel = RegressorChain(base_estimator=XGBRegressor())","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:04.507762Z","iopub.execute_input":"2022-04-17T18:08:04.5081Z","iopub.status.idle":"2022-04-17T18:08:04.514316Z","shell.execute_reply.started":"2022-04-17T18:08:04.508039Z","shell.execute_reply":"2022-04-17T18:08:04.513455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y)\n\ny_pred = pd.DataFrame(\n    model.predict(X),\n    index=y.index,\n    columns=y.columns,\n).clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:04.515745Z","iopub.execute_input":"2022-04-17T18:08:04.516148Z","iopub.status.idle":"2022-04-17T18:08:19.570094Z","shell.execute_reply.started":"2022-04-17T18:08:04.516113Z","shell.execute_reply":"2022-04-17T18:08:19.569335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FAMILY = 'BEAUTY'\nSTART = '2017-04-01'\nEVERY = 16\n\ny_pred_ = y_pred.xs(FAMILY, level='family', axis=0).loc[START:]\ny_ = family_sales.loc[START:, 'sales'].loc[:, FAMILY]\n\nfig, ax = plt.subplots(1, 1, figsize=(11, 4))\nax = y_.plot(**plot_params, ax=ax, alpha=0.5)\nax = plot_multistep(y_pred_, ax=ax, every=EVERY)\n_ = ax.legend([FAMILY, FAMILY + ' Forecast'])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:19.571187Z","iopub.execute_input":"2022-04-17T18:08:19.571971Z","iopub.status.idle":"2022-04-17T18:08:20.176623Z","shell.execute_reply.started":"2022-04-17T18:08:19.571926Z","shell.execute_reply":"2022-04-17T18:08:20.175884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for category in family_category.values():\n    FAMILY = category\n    START = '2017-04-01'\n    EVERY = 16\n\n    y_pred_ = y_pred.xs(FAMILY, level='family', axis=0).loc[START:]\n    y_ = family_sales.loc[START:, 'sales'].loc[:, FAMILY]\n\n    fig, ax = plt.subplots(1, 1, figsize=(11, 4))\n    ax = y_.plot(**plot_params, ax=ax, alpha=0.5)\n    ax = plot_multistep(y_pred_, ax=ax, every=EVERY)\n    _ = ax.legend([FAMILY, FAMILY + ' Forecast'])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:08:20.177643Z","iopub.execute_input":"2022-04-17T18:08:20.178518Z","iopub.status.idle":"2022-04-17T18:08:40.434925Z","shell.execute_reply.started":"2022-04-17T18:08:20.178465Z","shell.execute_reply":"2022-04-17T18:08:40.434172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"School and office supplies show funny chart.","metadata":{}},{"cell_type":"markdown","source":"**Tutorial done**\n\nMore clean up to do","metadata":{}},{"cell_type":"markdown","source":"Thanks for all\n\nhttps://www.kaggle.com/kashishrastogi/store-sales-forecasting\n\nhttps://www.kaggle.com/shivamb/store-sales-forecasting-exploration\n\nhttps://www.kaggle.com/drcapa/storesales-ts-starter\n\nhttps://www.kaggle.com/kalilurrahman/store-sales-eda-prediction-with-ts\n\nhttps://www.kaggle.com/shrutisaxena/store-sales-eda-using-plotly\n\nhttps://www.kaggle.com/veleirx/store-sales-fast-eda#2.-Stores\n\nSpecial thanks for Kaggle team member, Ryan Holbrook. \n\nhttps://www.kaggle.com/learn/time-series","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}